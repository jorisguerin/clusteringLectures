{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b7e49be",
   "metadata": {},
   "source": [
    "# Hands-on clustering #2:\n",
    "## Recommender system using Non-negative Matrix Factorization: MovieLens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747dbb85",
   "metadata": {},
   "source": [
    "## 2. Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd58e63",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67da683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacb2b20",
   "metadata": {},
   "source": [
    "### 2.1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea78062",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/ml-100k/u.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27460/1672309649.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading ratings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"User ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Movie ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Rating\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mratings_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data/ml-100k/u.data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Libraries/miniconda3/envs/clustering_lectures/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Libraries/miniconda3/envs/clustering_lectures/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Libraries/miniconda3/envs/clustering_lectures/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Libraries/miniconda3/envs/clustering_lectures/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Libraries/miniconda3/envs/clustering_lectures/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Libraries/miniconda3/envs/clustering_lectures/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Libraries/miniconda3/envs/clustering_lectures/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Libraries/miniconda3/envs/clustering_lectures/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/ml-100k/u.data'"
     ]
    }
   ],
   "source": [
    "# Loading ratings \n",
    "names = [\"User ID\", \"Movie ID\", \"Rating\"]\n",
    "ratings_df = pd.read_csv(\"Data/ml-100k/u.data\", sep=\"\\t\", usecols=[0,1,2], names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349ecba6",
   "metadata": {},
   "source": [
    "### 2.2 Understand the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c93418e",
   "metadata": {},
   "source": [
    "#### Display first few columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa3332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3245b194",
   "metadata": {},
   "source": [
    "#### Check data dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01631b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ratings = ratings_df.shape[0]\n",
    "n_users = len(ratings_df[\"User ID\"].unique())\n",
    "n_items = len(ratings_df[\"Movie ID\"].unique())\n",
    "\n",
    "print(\"Total number of ratings in the dataset: %i\" % (n_ratings))\n",
    "print(\"Number of persons who rated movies: %i\" % (n_users))\n",
    "print(\"Number of rated movies: %i\" % (n_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e61641",
   "metadata": {},
   "source": [
    "#### Statistics of the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20163e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = ratings_df[\"Rating\"].describe()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40155bf7",
   "metadata": {},
   "source": [
    "### 2.3. Histogram of the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ratings_df[\"Rating\"], bins=range(1, 7), align=\"left\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89585603",
   "metadata": {},
   "source": [
    "##### Interpretation\n",
    "\n",
    "- We might want to normalize accross the users, to ensure that each have them have the same rating scales.\\\n",
    "- However, we need to be careful in the transformation we apply to the data. Indeed, bringing the data to standard normal distribution would break the non-negativity of the data, and we could not apply NMF anymore.\\\n",
    "- For this study, no normalization will be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc518b",
   "metadata": {},
   "source": [
    "### 2.4. Ratings per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162cb655",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_list = range(1, n_users + 1)\n",
    "n_ratings = [np.count_nonzero(ratings_df[\"User ID\"] == i) for i in users_list]\n",
    "n_ratings = np.array(n_ratings)\n",
    "\n",
    "binwidth = 10\n",
    "bins = np.arange(min(n_ratings), max(n_ratings)+binwidth, binwidth)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(n_ratings, bins=bins, align=\"left\")\n",
    "plt.xlabel(\"Number of ratings\")\n",
    "plt.ylabel(\"Frequency: number of users with this much ratings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28735700",
   "metadata": {},
   "source": [
    "#### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3b1f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ratings_df = pd.DataFrame(n_ratings)\n",
    "summary = n_ratings_df.describe()\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57122b14",
   "metadata": {},
   "source": [
    "##### Interpretation\n",
    "\n",
    "- The average number of ratings per user is below fifty.\n",
    "- The minimum is twenty (that's how the dataset is built)\n",
    "- Some users rated many movies (more than 700)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82da49bb",
   "metadata": {},
   "source": [
    "### 2.5. Average ratings per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903c289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_list = range(1, n_items + 1)\n",
    "mean_ratings = [ratings_df[\"Rating\"][ratings_df[\"Movie ID\"] == i].mean() for i in movies_list]\n",
    "mean_ratings = np.array(mean_ratings)\n",
    "\n",
    "binwidth = 0.1\n",
    "bins = np.arange(min(mean_ratings), max(mean_ratings)+binwidth, binwidth)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(mean_ratings, bins=bins, align=\"mid\")\n",
    "plt.xlabel(\"Average rating\")\n",
    "plt.ylabel(\"Frequency: number of movies with this average rating\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a86b407",
   "metadata": {},
   "source": [
    "##### Interpretation\n",
    "\n",
    "- Spikes on exact values: several movies had unanimous ratings.\n",
    "- Spikes on 1 and 5: Some users might have a binary rating scale (like or dislike)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200b9dab",
   "metadata": {},
   "source": [
    "#### Find movies with ratings 1 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7264806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading movies titles\n",
    "movie_titles = pd.read_csv(\"Data/ml-100k/u.item\", sep=\"|\", header=None, usecols=[1], \n",
    "                           encoding='iso-8859-1', names=[\"Title\"])\n",
    "\n",
    "bad_movies, good_movies = [], []\n",
    "for i in range(len(mean_ratings)):\n",
    "    if mean_ratings[i] == 1:\n",
    "        bad_movies.append(movie_titles[\"Title\"][i])\n",
    "    if mean_ratings[i] == 5:\n",
    "        good_movies.append(movie_titles[\"Title\"][i])\n",
    "\n",
    "print(\"Example of movie with rating of 1:\", np.random.choice(bad_movies))\n",
    "print(\"Example of movie with rating of 5:\", np.random.choice(good_movies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23ccc7a",
   "metadata": {},
   "source": [
    "## 3. Applying NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c404c0",
   "metadata": {},
   "source": [
    "### 3.1. Build the user-item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974a0670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "users = ratings_df[\"User ID\"].values\n",
    "movies = ratings_df[\"Movie ID\"].values\n",
    "rating = ratings_df[\"Rating\"].values\n",
    "\n",
    "matrix_sparse = sparse.csr_matrix((rating, (users, movies)), shape=(n_users+1, n_items+1))\n",
    "R = matrix_sparse.todense()\n",
    "R = np.array(R[1:, 1:])\n",
    "\n",
    "print(\"Verify rating of user 196 for movie 242 (first row in data file): \", R[195, 241])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcab4fec",
   "metadata": {},
   "source": [
    "### 3.2. Sparsity of user-item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb8e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = 1 - len(R.nonzero()[0]) / (R.shape[0] * R.shape[1])\n",
    "print(\"Sparsity of R: %0.2f%%\" % (sparsity * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d24431f",
   "metadata": {},
   "source": [
    "##### Interpretation\n",
    "\n",
    "6.30% of the user-item ratings have a value. Missing values are filled with zeros but they do not represent zero on the same scale as the ratings, they are simply empty entries. Ratings are defined from 1 to 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e076f7e",
   "metadata": {},
   "source": [
    "### 3.3 Apply NMF with 20 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be3b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(n_components=20, init=\"nndsvda\", max_iter=int(1e3))\n",
    "nmf.fit(R)\n",
    "W = nmf.transform(R)\n",
    "H = nmf.components_\n",
    "\n",
    "print(\"Number of iterations: \", nmf.n_iter_)\n",
    "print(\"Movies features shape (transpose(H)): \", H.T.shape)\n",
    "print(\"Users features shape (W): \", W.shape)\n",
    "print(\"Reconstruction of R shape (W.H): \", W.dot(H).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f6a4c",
   "metadata": {},
   "source": [
    "##### Interpretation\n",
    "\n",
    "The algorithm converged, the shapes of the matrices are as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6463a8e7",
   "metadata": {},
   "source": [
    "### 3.4. Average reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceffd6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_pred = W.dot(H)\n",
    "\n",
    "print(\"Average reconstruction error: \", np.linalg.norm(R - R_pred) / (R.shape[0]*R.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af47b43f",
   "metadata": {},
   "source": [
    "### 3.5. Clip values outside rating scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c08120",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(R)\n",
    "R_pred = W.dot(H)\n",
    "R_pred[R_pred > 5] = 5.\n",
    "R_pred[R_pred < 1] = 1.\n",
    "\n",
    "print(R_pred.astype(np.int8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e6a6c0",
   "metadata": {},
   "source": [
    "##### Interpretation\n",
    "\n",
    "We want to make recommendations to the users. In other words, we want to estimate the rating a movie would get when this rating does not exist. This way, we give a valid rating to all of the movies in the new reconstructed matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a1e133",
   "metadata": {},
   "source": [
    "## 4. Make recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a76416",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_recommendations = 5\n",
    "user_idx = 12\n",
    "ratings_user = R[user_idx, :]\n",
    "predictions_user = R_pred[user_idx, :]\n",
    "\n",
    "print(\"Preferred movies for user %i:\" % user_idx)\n",
    "print(\"\\nTitle | Rating\\n-------------------------------\")\n",
    "favorite_movies_index = np.argsort(-ratings_user)\n",
    "for i in range(n_recommendations):\n",
    "    index = favorite_movies_index[i]\n",
    "    print(movie_titles[\"Title\"][index], \" | \", ratings_user[index])\n",
    "\n",
    "unseen_indices = np.where(ratings_user == 0)[0]\n",
    "predictions_unseen = predictions_user[unseen_indices]\n",
    "print(\"\\n\\nRecommended movies for user %i:\" % user_idx)\n",
    "print(\"\\nTitle | Rating\\n-------------------------------\")\n",
    "predicted_movies_index = np.argsort(-predictions_unseen)\n",
    "for i in range(n_recommendations):\n",
    "    index = unseen_indices[predicted_movies_index[i]]\n",
    "    print(movie_titles[\"Title\"][index], \" | \", predictions_user[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61072027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new user profile:\n",
    "my_ratings = np.zeros((1682,1), dtype=int)\n",
    "my_ratings[0] = 4 \n",
    "my_ratings[1] = 4 \n",
    "my_ratings[10] = 1 \n",
    "my_ratings[15] = 3\n",
    "my_ratings[27] = 4\n",
    "my_ratings[34] = 1\n",
    "my_ratings[49] = 1\n",
    "my_ratings[55] = 1\n",
    "my_ratings[61] = 1\n",
    "my_ratings[68] = 5\n",
    "my_ratings[70] = 4\n",
    "my_ratings[81] = 4\n",
    "my_ratings[87] = 2\n",
    "my_ratings[94] = 4\n",
    "my_ratings[120] = 2\n",
    "my_ratings[171] = 1\n",
    "my_ratings[173] = 4\n",
    "my_ratings[175] = 1\n",
    "my_ratings[182] = 1\n",
    "my_ratings[194] = 2\n",
    "my_ratings[203] = 5\n",
    "my_ratings[209] = 5\n",
    "my_ratings[221] = 1\n",
    "my_ratings[234] = 2\n",
    "my_ratings[312] = 3\n",
    "my_ratings[317] = 3\n",
    "my_ratings[322] = 3\n",
    "my_ratings[342] = 1\n",
    "my_ratings[378] = 1\n",
    "my_ratings[379] = 1\n",
    "my_ratings[392] = 3\n",
    "my_ratings[404] = 2\n",
    "my_ratings[422] = 4\n",
    "my_ratings[542] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad55d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "newR = np.r_[R, my_ratings.T]\n",
    "\n",
    "new_nmf = NMF(n_components=20, init=\"nndsvda\", max_iter=int(1e3))\n",
    "new_nmf.fit(R)\n",
    "newW = new_nmf.transform(R)\n",
    "newH = new_nmf.components_\n",
    "\n",
    "print(\"Number of iterations: \", nmf.n_iter_)\n",
    "print(\"Movies features shape (transpose(H)): \", H.T.shape)\n",
    "print(\"Users features shape (W): \", W.shape)\n",
    "print(\"Reconstruction of R shape (W.H): \", W.dot(H).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beccb45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newR)\n",
    "newR_pred = newW.dot(newH)\n",
    "newR_pred[newR_pred > 5] = 5.\n",
    "newR_pred[newR_pred < 1] = 1.\n",
    "\n",
    "print(newR_pred.astype(np.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e076086",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_recommendations = 5\n",
    "user_idx = -1\n",
    "ratings_user = newR[user_idx, :]\n",
    "predictions_user = newR_pred[user_idx, :]\n",
    "\n",
    "print(\"Preferred movies for user %i:\" % user_idx)\n",
    "print(\"\\nTitle | Rating\\n-------------------------------\")\n",
    "favorite_movies_index = np.argsort(-ratings_user)\n",
    "for i in range(n_recommendations):\n",
    "    index = favorite_movies_index[i]\n",
    "    print(movie_titles[\"Title\"][index], \" | \", ratings_user[index])\n",
    "\n",
    "unseen_indices = np.where(ratings_user == 0)[0]\n",
    "predictions_unseen = predictions_user[unseen_indices]\n",
    "print(\"\\n\\nRecommended movies for user %i:\" % user_idx)\n",
    "print(\"\\nTitle | Rating\\n-------------------------------\")\n",
    "predicted_movies_index = np.argsort(-predictions_unseen)\n",
    "for i in range(n_recommendations):\n",
    "    index = unseen_indices[predicted_movies_index[i]]\n",
    "    print(movie_titles[\"Title\"][index], \" | \", predictions_user[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d6429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "movies_sim = cosine_similarity(H.T)\n",
    "plt.imshow(movies_sim)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d759d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_recommendations = 5\n",
    "\n",
    "watch_index = np.random.randint(0, len(movie_titles[\"Title\"]))\n",
    "print(\"Currently watching: \", movie_titles[\"Title\"][watch_index])\n",
    "\n",
    "movies_similarities = movies_sim[watch_index, :]\n",
    "suggestions = np.argsort(-movies_similarities)[1:n_recommendations + 1]\n",
    "\n",
    "print(\"\\n\\nRecommended movies for user:\")\n",
    "print(\"\\nTitle | Similarity\\n-------------------------------\")\n",
    "for i in suggestions:\n",
    "    print(movie_titles[\"Title\"][i], \" | \", movies_similarities[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d0ca4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
